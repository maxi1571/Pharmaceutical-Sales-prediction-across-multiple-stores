{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, norm\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pickle\n",
    "from urllib.parse import urlparse\n",
    "import dvc.api\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "import mlflow.keras\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and configure logger\n",
    "logging.basicConfig(filename=\"newfile.log\",\n",
    "                    format='%(asctime)s %(message)s',\n",
    "                    filemode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an object\n",
    "logger=logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ['data/store.csv', 'data/train.csv', 'data/test.csv']\n",
    "version = ['store_v1', 'train_v1', 'test_v1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    repo = '/home/michael/Pharmaceutical-Sales-prediction-across-multiple-stores'\n",
    "    data_url = dvc.api.get_url(\n",
    "        path = path[0],\n",
    "        repo = repo,\n",
    "        rev=version[0]\n",
    "        )\n",
    "    data_url2 = dvc.api.get_url(\n",
    "        path = path[1],\n",
    "        repo = repo,\n",
    "        rev=version[1]\n",
    "        )\n",
    "    data_url3 = dvc.api.get_url(\n",
    "        path = path[2],\n",
    "        repo = repo,\n",
    "        rev=version[2]\n",
    "        )\n",
    "\n",
    "    df_store = pd.read_csv(data_url)\n",
    "    df_train = pd.read_csv(data_url2)\n",
    "    df_test = pd.read_csv(data_url3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1017209, 18)\n",
      "(41088, 17)\n"
     ]
    }
   ],
   "source": [
    "# merge the train/test sets with the stores set\n",
    "merged_train = pd.merge(left = df_train, right = df_store, how = 'inner', left_on = 'Store', right_on = 'Store')\n",
    "merged_test = pd.merge(left = df_test, right = df_store, how = 'inner', left_on = 'Store', right_on = 'Store')\n",
    "print(merged_train.shape)\n",
    "print(merged_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_train = merged_train.copy()\n",
    "deep_test = merged_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train, test):\n",
    "    \n",
    "    # '''preprocessing'''\n",
    "    global train_features, test_features, train_target, categorical, numerical\n",
    "\n",
    "    # train and target features\n",
    "    train_features = train.drop(['Sales', 'Customers'], axis = 1) #drop the target feature + customers (~ will not be used for prediction)\n",
    "    train_target  = train[['Sales']]\n",
    "    test_features = test.drop(['Id'], axis = 1) #drop id, it's required only during submission\n",
    "\n",
    "    #feature generation + transformations\n",
    "    train_features['Date'] = pd.to_datetime(train_features.Date)\n",
    "    train_features['Month'] = train_features.Date.dt.month.to_list()\n",
    "    train_features['Year'] = train_features.Date.dt.year.to_list()\n",
    "    train_features['Day'] = train_features.Date.dt.day.to_list()\n",
    "    train_features['WeekOfYear'] = train_features.Date.dt.weekofyear.to_list()\n",
    "    train_features['DayOfWeek'] = train_features.Date.dt.dayofweek.to_list()\n",
    "    train_features['weekday'] = 1        # Initialize the column with default value of 1\n",
    "    train_features.loc[train_features['DayOfWeek'] == 5, 'weekday'] = 0\n",
    "    train_features.loc[train_features['DayOfWeek'] == 6, 'weekday'] = 0\n",
    "    train_features = train_features.drop(['Store'], axis = 1)\n",
    "\n",
    "    test_features['Date'] = pd.to_datetime(test_features.Date)\n",
    "    test_features['Month'] = test_features.Date.dt.month.to_list()\n",
    "    test_features['Year'] = test_features.Date.dt.year.to_list()\n",
    "    test_features['Day'] = test_features.Date.dt.day.to_list()\n",
    "    test_features['WeekOfYear'] = test_features.Date.dt.weekofyear.to_list()\n",
    "    test_features['DayOfWeek'] = test_features.Date.dt.dayofweek.to_list()\n",
    "    test_features['weekday'] = 1        # Initialize the column with default value of 1\n",
    "    test_features.loc[test_features['DayOfWeek'] == 5, 'weekday'] = 0\n",
    "    test_features.loc[test_features['DayOfWeek'] == 6, 'weekday'] = 0\n",
    "    test_features = test_features.drop(['Store'], axis = 1)\n",
    "\n",
    "\n",
    "    # numerical and categorical columns (train set)\n",
    "    categorical = []\n",
    "    numerical = []\n",
    "    timestamp = []\n",
    "\n",
    "    for col in train_features.columns:\n",
    "        if train_features[col].dtype == object:\n",
    "            categorical.append(col)\n",
    "        elif train_features[col].dtype in ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']:\n",
    "            numerical.append(col)\n",
    "        else:\n",
    "            timestamp.append(col)\n",
    "\n",
    "    # Keep selected columns only\n",
    "    my_cols = categorical + numerical + timestamp\n",
    "    train_features = train_features[my_cols].copy()\n",
    "    test_features = test_features[my_cols].copy()\n",
    "    features = pd.concat([train_features, test_features]) #merge the features columns for uniform preprocessing\n",
    "\n",
    "    # change dtypes for uniformity in preprocessing\n",
    "    features.CompetitionOpenSinceMonth = features.CompetitionOpenSinceMonth.astype('Int64') \n",
    "    features.CompetitionOpenSinceYear = features.CompetitionOpenSinceYear.astype('Int64')\n",
    "    features.Promo2SinceWeek = features.Promo2SinceWeek.astype('Int64') \n",
    "    features.Promo2SinceYear = features.Promo2SinceYear.astype('Int64')\n",
    "    features[\"StateHoliday\"].loc[features[\"StateHoliday\"] == 0] = \"0\"\n",
    "\n",
    "\n",
    "\n",
    "    # ''' actual preprocessing: the mighty pipeline '''\n",
    "    # numeric\n",
    "    for col in ['CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2SinceWeek', 'Promo2SinceYear']:\n",
    "        features[col] = features[col].fillna((int(features[col].mean()))) \n",
    "    features.PromoInterval = features.PromoInterval.fillna(features.PromoInterval.mode()[0])\n",
    "    features.Open = features.Open.fillna(features.Open.mode()[0])\n",
    "    features = pd.get_dummies(features, columns=['StoreType', 'Assortment', 'PromoInterval', 'StateHoliday'])\n",
    "    \n",
    "    scaler = RobustScaler()\n",
    "    c = ['DayOfWeek', 'Open', 'Promo', 'SchoolHoliday', 'CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear',\n",
    "    'Promo2', 'Promo2SinceWeek', 'Promo2SinceYear', 'WeekOfYear', 'Month', 'Year', 'Day', 'WeekOfYear', 'weekday']\n",
    "    features[numerical] = scaler.fit_transform(features[numerical].values)\n",
    "\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>CompetitionOpenSinceMonth</th>\n",
       "      <th>CompetitionOpenSinceYear</th>\n",
       "      <th>Promo2</th>\n",
       "      <th>Promo2SinceWeek</th>\n",
       "      <th>Promo2SinceYear</th>\n",
       "      <th>...</th>\n",
       "      <th>Assortment_a</th>\n",
       "      <th>Assortment_b</th>\n",
       "      <th>Assortment_c</th>\n",
       "      <th>PromoInterval_Feb,May,Aug,Nov</th>\n",
       "      <th>PromoInterval_Jan,Apr,Jul,Oct</th>\n",
       "      <th>PromoInterval_Mar,Jun,Sept,Dec</th>\n",
       "      <th>StateHoliday_0</th>\n",
       "      <th>StateHoliday_a</th>\n",
       "      <th>StateHoliday_b</th>\n",
       "      <th>StateHoliday_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.172078</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.172078</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.172078</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.172078</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.172078</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DayOfWeek  Open  Promo  SchoolHoliday  CompetitionDistance  \\\n",
       "0       0.25   0.0    1.0            1.0            -0.172078   \n",
       "1       0.00   0.0    1.0            1.0            -0.172078   \n",
       "2      -0.25   0.0    1.0            1.0            -0.172078   \n",
       "3      -0.50   0.0    1.0            1.0            -0.172078   \n",
       "4      -0.75   0.0    1.0            1.0            -0.172078   \n",
       "\n",
       "   CompetitionOpenSinceMonth  CompetitionOpenSinceYear  Promo2  \\\n",
       "0                   0.666667                       0.0    -1.0   \n",
       "1                   0.666667                       0.0    -1.0   \n",
       "2                   0.666667                       0.0    -1.0   \n",
       "3                   0.666667                       0.0    -1.0   \n",
       "4                   0.666667                       0.0    -1.0   \n",
       "\n",
       "   Promo2SinceWeek  Promo2SinceYear  ...  Assortment_a  Assortment_b  \\\n",
       "0              0.0              0.0  ...             1             0   \n",
       "1              0.0              0.0  ...             1             0   \n",
       "2              0.0              0.0  ...             1             0   \n",
       "3              0.0              0.0  ...             1             0   \n",
       "4              0.0              0.0  ...             1             0   \n",
       "\n",
       "   Assortment_c  PromoInterval_Feb,May,Aug,Nov  PromoInterval_Jan,Apr,Jul,Oct  \\\n",
       "0             0                              0                              1   \n",
       "1             0                              0                              1   \n",
       "2             0                              0                              1   \n",
       "3             0                              0                              1   \n",
       "4             0                              0                              1   \n",
       "\n",
       "   PromoInterval_Mar,Jun,Sept,Dec  StateHoliday_0  StateHoliday_a  \\\n",
       "0                               0               1               0   \n",
       "1                               0               1               0   \n",
       "2                               0               1               0   \n",
       "3                               0               1               0   \n",
       "4                               0               1               0   \n",
       "\n",
       "   StateHoliday_b  StateHoliday_c  \n",
       "0               0               0  \n",
       "1               0               0  \n",
       "2               0               0  \n",
       "3               0               0  \n",
       "4               0               0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = preprocess_data(merged_train, merged_test)\n",
    "features = features.drop(['Date'], axis = 1)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((813767, 29), (203442, 29), (813767,), (203442,), (41088, 29))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transfomer data to time series problem\n",
    "def reconstruct_sets(features):\n",
    "    global x_train, x_val, y_train, y_val\n",
    "    # global train_set\n",
    "    # original train and test sets\n",
    "    x_train = features.iloc[:len(train_features), :]\n",
    "    x_test = features.iloc[len(train_features):, :]\n",
    "    y_train = train_target\n",
    "    # train_set = pd.concat([x_train, y_train], axis=1)\n",
    "\n",
    "    # updated train and validation sets\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = .20, random_state = 0)\n",
    "\n",
    "\n",
    "    return x_train, x_val, y_train, y_val, x_test\n",
    "\n",
    "x_train, x_val, y_train, y_val, x_test = reconstruct_sets(features)\n",
    "# log transformation on target variable\n",
    "y_train = np.log1p(y_train['Sales'])\n",
    "y_val = np.log1p(y_val['Sales'])\n",
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error for xgb on validation data = 0.18399730159320643\n",
      "Mean squared error for xgb on validation data = 0.06874030684376421\n",
      "Mean R2 score for xgb on validation data = 0.9937185103595642\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    alpha = 11\n",
    "    learning_rate = 0.09\n",
    "    xgb = XGBRegressor(learning_rate = learning_rate, alpha = alpha, random_state = 5)\n",
    "    xgb.fit(x_train, y_train)\n",
    "    xgb_pred = xgb.predict(x_val)\n",
    "    print(\"Mean absolute error for xgb on validation data =\", mean_absolute_error(y_val, xgb_pred))\n",
    "    print(\"Mean squared error for xgb on validation data =\", mean_squared_error(y_val, xgb_pred))\n",
    "    print(\"Mean R2 score for xgb on validation data =\", r2_score(y_val, xgb_pred))\n",
    "\n",
    "    mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "    mlflow.log_param(\"alpha\", alpha)\n",
    "    mlflow.log_metric(\"mse\", mean_squared_error(y_val, xgb_pred))\n",
    "    mlflow.log_metric(\"r2\", r2_score(y_val, xgb_pred))\n",
    "    mlflow.log_metric(\"mae\", mean_absolute_error(y_val, xgb_pred))\n",
    "\n",
    "    tracking_url_type_store = urlparse(mlflow.get_tracking_uri(),).scheme\n",
    "\n",
    "    # Model registry does not work with file store\n",
    "    if tracking_url_type_store != \"file\":\n",
    "\n",
    "        mlflow.xgboost.log_model(xgb, \"xgb model\", registered_model_name=\"XGBRegressor\")\n",
    "    else:\n",
    "        mlflow.xgboost.log_model(xgb, \"xgb model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet model (normalize=1.000000, l1_copy_x=0.000000):\n",
      "Mean squared error for SLR on validation data = 0.11852351781694762\n",
      "Mean absolute error for SLR on validation data = 0.2527641257902306\n",
      "Mean R2 score for xgb on validation data = 0.9891693202503837\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    normalize = True\n",
    "    copy_X = False\n",
    "    regressor = LinearRegression(fit_intercept=True, normalize=normalize, copy_X=copy_X, n_jobs=None)\n",
    "    regressor.fit(x_train, y_train)\n",
    "    regressor_pred = regressor.predict(x_val)\n",
    "    \n",
    "    print(\"Elasticnet model (normalize=%f, l1_copy_x=%f):\" % (normalize, copy_X))\n",
    "    print(\"Mean squared error for SLR on validation data =\", mean_squared_error(y_val, regressor_pred))\n",
    "    print(\"Mean absolute error for SLR on validation data =\", mean_absolute_error(y_val, regressor_pred))\n",
    "    print(\"Mean R2 score for xgb on validation data =\", r2_score(y_val, regressor_pred))\n",
    "\n",
    "    mlflow.log_param(\"normalize\", normalize)\n",
    "    mlflow.log_param(\"copy_X\", copy_X)\n",
    "    mlflow.log_metric(\"mse\", mean_squared_error(y_val, regressor_pred))\n",
    "    mlflow.log_metric(\"r2\", r2_score(y_val, regressor_pred))\n",
    "    mlflow.log_metric(\"mae\", mean_absolute_error(y_val, regressor_pred))\n",
    "\n",
    "    tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "    # Model registry does not work with file store\n",
    "    if tracking_url_type_store != \"file\":\n",
    "\n",
    "        mlflow.sklearn.log_model(regressor, \"model\", registered_model_name=\"LinearRegression\")\n",
    "    else:\n",
    "        mlflow.sklearn.log_model(regressor, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error for RF on validation data = 0.018471459419053347\n",
      "Mean absolute error for RF on validation data = 0.07655209474693409\n",
      "Mean R2 score for xgb on validation data = 0.9983120779305186\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    n_estimators = 12\n",
    "    rfr=RandomForestRegressor(n_estimators=n_estimators)\n",
    "    rfr.fit(x_train,y_train)\n",
    "    y_pred = rfr.predict(x_val)\n",
    "    print(\"Mean squared error for RF on validation data =\", mean_squared_error(y_val, y_pred))\n",
    "    print(\"Mean absolute error for RF on validation data =\", mean_absolute_error(y_val, y_pred))\n",
    "    print(\"Mean R2 score for xgb on validation data =\", r2_score(y_val, y_pred))\n",
    "    mlflow.log_param(\"normalize\", n_estimators)\n",
    "    mlflow.log_metric(\"mse\", mean_squared_error(y_val, y_pred))\n",
    "    mlflow.log_metric(\"r2\", r2_score(y_val, y_pred))\n",
    "    mlflow.log_metric(\"mae\", mean_absolute_error(y_val, y_pred))\n",
    "\n",
    "    tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "    # Model registry does not work with file store\n",
    "    if tracking_url_type_store != \"file\":\n",
    "\n",
    "        mlflow.sklearn.log_model(rfr, \"model\", registered_model_name=\"RandomForestRegressor\")\n",
    "    else:\n",
    "        mlflow.sklearn.log_model(rfr, \"model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM deep learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>CompetitionOpenSinceMonth</th>\n",
       "      <th>CompetitionOpenSinceYear</th>\n",
       "      <th>Promo2</th>\n",
       "      <th>Promo2SinceWeek</th>\n",
       "      <th>Promo2SinceYear</th>\n",
       "      <th>...</th>\n",
       "      <th>Assortment_a</th>\n",
       "      <th>Assortment_b</th>\n",
       "      <th>Assortment_c</th>\n",
       "      <th>PromoInterval_Feb,May,Aug,Nov</th>\n",
       "      <th>PromoInterval_Jan,Apr,Jul,Oct</th>\n",
       "      <th>PromoInterval_Mar,Jun,Sept,Dec</th>\n",
       "      <th>StateHoliday_0</th>\n",
       "      <th>StateHoliday_a</th>\n",
       "      <th>StateHoliday_b</th>\n",
       "      <th>StateHoliday_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.172078</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.172078</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.172078</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.172078</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.172078</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DayOfWeek  Open  Promo  SchoolHoliday  CompetitionDistance  \\\n",
       "0       0.25   0.0    1.0            1.0            -0.172078   \n",
       "1       0.00   0.0    1.0            1.0            -0.172078   \n",
       "2      -0.25   0.0    1.0            1.0            -0.172078   \n",
       "3      -0.50   0.0    1.0            1.0            -0.172078   \n",
       "4      -0.75   0.0    1.0            1.0            -0.172078   \n",
       "\n",
       "   CompetitionOpenSinceMonth  CompetitionOpenSinceYear  Promo2  \\\n",
       "0                   0.666667                       0.0    -1.0   \n",
       "1                   0.666667                       0.0    -1.0   \n",
       "2                   0.666667                       0.0    -1.0   \n",
       "3                   0.666667                       0.0    -1.0   \n",
       "4                   0.666667                       0.0    -1.0   \n",
       "\n",
       "   Promo2SinceWeek  Promo2SinceYear  ...  Assortment_a  Assortment_b  \\\n",
       "0              0.0              0.0  ...             1             0   \n",
       "1              0.0              0.0  ...             1             0   \n",
       "2              0.0              0.0  ...             1             0   \n",
       "3              0.0              0.0  ...             1             0   \n",
       "4              0.0              0.0  ...             1             0   \n",
       "\n",
       "   Assortment_c  PromoInterval_Feb,May,Aug,Nov  PromoInterval_Jan,Apr,Jul,Oct  \\\n",
       "0             0                              0                              1   \n",
       "1             0                              0                              1   \n",
       "2             0                              0                              1   \n",
       "3             0                              0                              1   \n",
       "4             0                              0                              1   \n",
       "\n",
       "   PromoInterval_Mar,Jun,Sept,Dec  StateHoliday_0  StateHoliday_a  \\\n",
       "0                               0               1               0   \n",
       "1                               0               1               0   \n",
       "2                               0               1               0   \n",
       "3                               0               1               0   \n",
       "4                               0               1               0   \n",
       "\n",
       "   StateHoliday_b  StateHoliday_c  \n",
       "0               0               0  \n",
       "1               0               0  \n",
       "2               0               0  \n",
       "3               0               0  \n",
       "4               0               0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features2 = preprocess_data(deep_train, deep_test)\n",
    "features2 = features2.drop(['Date'], axis = 1)\n",
    "features2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((813767, 35), (203442, 35), (813767,), (203442,), (41088, 29))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reconstruct train and test sets\n",
    "def reconstruct_sets(features, time_window):\n",
    "    global x_train, x_val, y_train, y_val\n",
    "    # global train_set\n",
    "    # original train and test sets\n",
    "    x_train = features.iloc[:len(train_features), :]\n",
    "    x_test = features.iloc[len(train_features):, :]\n",
    "    y_train = train_target\n",
    "    \n",
    "    # Transforming dataset to time series problem\n",
    "    scaler = RobustScaler()\n",
    "    for i in range(1, time_window+1):\n",
    "        x_train[\"Sales_\" + str(i)] = y_train.Sales.shift(i)\n",
    "        x_train.fillna(0.0, inplace=True)\n",
    "        x_train[\"Sales_\" + str(i)] = scaler.fit_transform(x_train[\"Sales_\" + str(i)].values.reshape(-1, 1))\n",
    "    x_train.fillna(0.0, inplace=True)\n",
    "    shift_test = x_train.copy()\n",
    "    # train_set = pd.concat([x_train, y_train], axis=1)\n",
    "\n",
    "    # updated train and validation sets\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = .20, random_state = 0)\n",
    "\n",
    "\n",
    "    return x_train, x_val, y_train, y_val, x_test\n",
    "\n",
    "x_train, x_val, y_train, y_val, x_test = reconstruct_sets(features2, 6)\n",
    "# log transformation on target variable\n",
    "y_train = np.log1p(y_train['Sales'])\n",
    "y_val = np.log1p(y_val['Sales'])\n",
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((813767, 1, 35), (203442, 1, 35))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_reshaped = x_train.values.reshape((x_train.shape[0], 1, x_train.shape[1]))\n",
    "x_val_reshaped = x_val.values.reshape((x_val.shape[0],1, x_val.shape[1]))\n",
    "x_train_reshaped.shape, x_val_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-31 17:59:02.872356: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-07-31 17:59:02.872556: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-07-31 17:59:12.259805: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-07-31 17:59:12.291704: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-07-31 17:59:12.291820: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-07-31 17:59:12.291884: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (michael): /proc/driver/nvidia/version does not exist\n",
      "2021-07-31 17:59:12.293901: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-31 17:59:12.295497: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 8)                 1408      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 1,426\n",
      "Trainable params: 1,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(8, activation='relu', input_shape=(x_train_reshaped.shape[1], x_train_reshaped.shape[2])))\n",
    "model_lstm.add(Dense(2))\n",
    "model_lstm.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Denses = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-31 17:59:17.286737: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 113927380 exceeds 10% of free system memory.\n",
      "2021-07-31 17:59:17.490775: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-07-31 17:59:17.592046: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 1999965000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "67814/67814 - 62s - loss: 0.2751 - mse: 0.2751 - val_loss: 0.0362 - val_mse: 0.0362\n",
      "Epoch 2/2\n",
      "67814/67814 - 61s - loss: 0.0380 - mse: 0.0380 - val_loss: 0.0320 - val_mse: 0.0320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-31 18:01:21.234625: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    history = model_lstm.fit(x_train_reshaped, y_train, validation_data=(x_val_reshaped, y_val),epochs=2, batch_size=12, verbose=2, shuffle=False)\n",
    "    train_loss=history.history['loss'][-1]\n",
    "    val_loss=history.history['val_loss'][-1]\n",
    "    mse = history.history['mse'][-1]\n",
    "    mlflow.log_param(\"network dense\", Denses)\n",
    "    mlflow.log_metric(\"loss\", train_loss)\n",
    "    mlflow.log_metric(\"val_loss\", val_loss)\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "\n",
    "    tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "    if tracking_url_type_store != \"file\":\n",
    "\n",
    "        mlflow.keras.log_model(model_lstm, \"LSTM model\", registered_model_name=\"Sequential\")\n",
    "    else:\n",
    "        mlflow.keras.log_model(model_lstm, \"LSTM model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-07-31 18:02:00 +0300] [5986] [INFO] Starting gunicorn 20.1.0\n",
      "[2021-07-31 18:02:00 +0300] [5986] [INFO] Listening at: http://127.0.0.1:5000 (5986)\n",
      "[2021-07-31 18:02:00 +0300] [5986] [INFO] Using worker: sync\n",
      "[2021-07-31 18:02:00 +0300] [5989] [INFO] Booting worker with pid: 5989\n",
      "^C\n",
      "[2021-07-31 18:49:01 +0300] [5986] [INFO] Handling signal: int\n",
      "[2021-07-31 18:49:01 +0300] [5989] [INFO] Worker exiting (pid: 5989)\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
